{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7c1e74-f42e-4f29-9e16-b264dc1da9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from utils import preprocess_all_images\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe6f376-42c9-4e3f-9a30-9296d9f54a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attempts = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64f36f29-02b1-4946-ae17-ddb86d2c6d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../assets/apple.png', '../assets/bears.png', '../assets/bird.png', '../assets/boat.png', '../assets/cat.png', '../assets/cows.png', '../assets/dog.png', '../assets/laptop.png', '../assets/objects1.png', '../assets/objects2.png', '../assets/objects3.png', '../assets/parrot.png', '../assets/people.png',\n",
       "       '../assets/plane.png', '../assets/ship.png', '../assets/sport_objects.png'], dtype='<U27')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "images = [f\"../assets/{i}\" for i in os.listdir('../assets') if os.path.isfile(f\"../assets/{i}\")]\n",
    "images = np.array(images)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5e8e8f0-a7f0-4636-9a3c-ea05f8176ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_inference(model_variant, data, max_batch_size=16):\n",
    "    output_file_path = \"../ultralytics_result.csv\"\n",
    "    \n",
    "    if not os.path.exists(output_file_path):\n",
    "        with open(output_file_path, 'w') as f:\n",
    "            row = \"Backend,Model,NumThreads,\" + \\\n",
    "                \",\".join(map(str, list(range(1, max_batch_size+1)))) + \"\\n\"\n",
    "            f.write(row)\n",
    "    with open(output_file_path, 'a') as f:\n",
    "        row = f\"Ultralytics,{model_variant},-1,\" + \",\".join(map(str, data)) + \"\\n\"\n",
    "        f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5901d39c-a1b6-4f5d-bfe9-824308a123b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = preprocess_all_images(\"../assets\")\n",
    "batch = np.stack(image_batch, axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba67d428-03a5-480c-b68a-e01583a10a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing s...\n",
      "Batch size=1 took 407.324 ms, 407.324 ms/img\n",
      "Batch size=2 took 236.284 ms, 118.142 ms/img\n",
      "Batch size=3 took 306.692 ms, 102.231 ms/img\n",
      "Batch size=4 took 415.430 ms, 103.858 ms/img\n",
      "Batch size=5 took 513.149 ms, 102.630 ms/img\n",
      "Batch size=6 took 685.806 ms, 114.301 ms/img\n",
      "Batch size=7 took 844.803 ms, 120.686 ms/img\n",
      "Batch size=8 took 857.148 ms, 107.144 ms/img\n",
      "Batch size=9 took 1098.335 ms, 122.037 ms/img\n",
      "Batch size=10 took 1178.515 ms, 117.852 ms/img\n",
      "Batch size=11 took 1501.073 ms, 136.461 ms/img\n",
      "Batch size=12 took 1518.247 ms, 126.521 ms/img\n",
      "Batch size=13 took 1724.683 ms, 132.668 ms/img\n",
      "Batch size=14 took 1931.461 ms, 137.962 ms/img\n",
      "Batch size=15 took 1894.012 ms, 126.267 ms/img\n",
      "Batch size=16 took 2005.368 ms, 125.335 ms/img\n",
      "\n",
      "Inferencing m...\n",
      "Batch size=1 took 196.932 ms, 196.932 ms/img\n",
      "Batch size=2 took 336.978 ms, 168.489 ms/img\n",
      "Batch size=3 took 481.297 ms, 160.432 ms/img\n",
      "Batch size=4 took 741.237 ms, 185.309 ms/img\n",
      "Batch size=5 took 948.949 ms, 189.790 ms/img\n",
      "Batch size=6 took 1088.969 ms, 181.495 ms/img\n",
      "Batch size=7 took 1396.713 ms, 199.530 ms/img\n",
      "Batch size=8 took 1716.585 ms, 214.573 ms/img\n",
      "Batch size=9 took 1930.416 ms, 214.491 ms/img\n",
      "Batch size=10 took 2173.822 ms, 217.382 ms/img\n",
      "Batch size=11 took 2395.552 ms, 217.777 ms/img\n",
      "Batch size=12 took 2626.476 ms, 218.873 ms/img\n",
      "Batch size=13 took 2701.179 ms, 207.783 ms/img\n",
      "Batch size=14 took 3212.156 ms, 229.440 ms/img\n",
      "Batch size=15 took 3667.198 ms, 244.480 ms/img\n",
      "Batch size=16 took 3993.772 ms, 249.611 ms/img\n",
      "\n",
      "Inferencing b...\n",
      "Batch size=1 took 248.396 ms, 248.396 ms/img\n",
      "Batch size=2 took 510.734 ms, 255.367 ms/img\n",
      "Batch size=3 took 734.561 ms, 244.854 ms/img\n",
      "Batch size=4 took 960.930 ms, 240.232 ms/img\n",
      "Batch size=5 took 1207.037 ms, 241.407 ms/img\n",
      "Batch size=6 took 1514.008 ms, 252.335 ms/img\n",
      "Batch size=7 took 1816.397 ms, 259.485 ms/img\n",
      "Batch size=8 took 2313.766 ms, 289.221 ms/img\n",
      "Batch size=9 took 2557.328 ms, 284.148 ms/img\n",
      "Batch size=10 took 2844.166 ms, 284.417 ms/img\n",
      "Batch size=11 took 3390.532 ms, 308.230 ms/img\n",
      "Batch size=12 took 3927.739 ms, 327.312 ms/img\n",
      "Batch size=13 took 4277.558 ms, 329.043 ms/img\n",
      "Batch size=14 took 4530.594 ms, 323.614 ms/img\n",
      "Batch size=15 took 4786.308 ms, 319.087 ms/img\n",
      "Batch size=16 took 5253.846 ms, 328.365 ms/img\n",
      "\n",
      "Inferencing l...\n",
      "Batch size=1 took 271.867 ms, 271.867 ms/img\n",
      "Batch size=2 took 535.749 ms, 267.874 ms/img\n",
      "Batch size=3 took 881.956 ms, 293.985 ms/img\n",
      "Batch size=4 took 1168.061 ms, 292.015 ms/img\n",
      "Batch size=5 took 1424.568 ms, 284.914 ms/img\n",
      "Batch size=6 took 1964.060 ms, 327.343 ms/img\n",
      "Batch size=7 took 2334.016 ms, 333.431 ms/img\n",
      "Batch size=8 took 2611.583 ms, 326.448 ms/img\n",
      "Batch size=9 took 2927.562 ms, 325.285 ms/img\n",
      "Batch size=10 took 3267.399 ms, 326.740 ms/img\n",
      "Batch size=11 took 3979.151 ms, 361.741 ms/img\n",
      "Batch size=12 took 4404.333 ms, 367.028 ms/img\n",
      "Batch size=13 took 5024.020 ms, 386.463 ms/img\n",
      "Batch size=14 took 5312.223 ms, 379.444 ms/img\n",
      "Batch size=15 took 5765.795 ms, 384.386 ms/img\n",
      "Batch size=16 took 6207.737 ms, 387.984 ms/img\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_variants = ['s', 'm', 'b', 'l']\n",
    "for model_variant in model_variants:\n",
    "    print(f\"Inferencing {model_variant}...\")\n",
    "    model = YOLO(f\"../models/{model_variant}/yolov10{model_variant}.pt\")\n",
    "    times = []\n",
    "    for batch_size in range(1, 17):\n",
    "        ms_time = []\n",
    "        for j in range(num_attempts):\n",
    "            random_idxs = random.sample(range(16), batch_size)\n",
    "            batch_sample = list(images[random_idxs])\n",
    "            t1 = time.time()\n",
    "            output = model(batch_sample, verbose=False, device='cpu')\n",
    "            t2 = time.time()\n",
    "            ms_time += [(t2-t1)*1000]\n",
    "        print(f\"Batch size={batch_size} took {np.mean(ms_time):.3f} ms, {np.mean(ms_time)/batch_size:.3f} ms/img\")\n",
    "        times += [np.mean(ms_time)/batch_size]\n",
    "    log_inference(model_variant, [float(t) for t in times])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614c4f1-865b-44ec-a2dc-3d0a3d8ab01e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics-venv",
   "language": "python",
   "name": "ultralytics-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
